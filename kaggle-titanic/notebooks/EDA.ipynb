{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preprocessing : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Preprocessing #####\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler, LabelBinarizer\n",
    "\n",
    "def preprocess(data: pd.DataFrame):\n",
    "    data.set_index(\"PassengerId\", inplace=True)\n",
    "\n",
    "    # Name and Ticket columns are useless here\n",
    "    # Cabin contains too much missing values so let's remove it too.\n",
    "    \n",
    "    #data = handle_names(data)\n",
    "    data = handle_family_size(data)\n",
    "    data.drop([\"Ticket\", \"Cabin\", \"Name\"], axis=1, inplace=True)\n",
    "    \n",
    "    # Handle missing values\n",
    "    median_age = data[\"Age\"].mean()\n",
    "    data[\"Age\"] = data[\"Age\"].fillna(median_age)\n",
    "    data[\"Embarked\"] = data[\"Embarked\"].fillna(\"S\")\n",
    "\n",
    "    # encode \"sex\" column (1->male, 0->female)\n",
    "    binarizer = LabelBinarizer()\n",
    "    sex_encoded = binarizer.fit_transform(data['Sex'])\n",
    "    data[\"Sex\"] = sex_encoded\n",
    "\n",
    "    # encode \"Embarked\" column (One-Hot Encoding)\n",
    "    data = Encode_OHE(data, \"Embarked\")\n",
    "    \n",
    "    # make sure we don't have any NaN values     \n",
    "    return data.fillna(data.median())\n",
    "\n",
    "def Encode_OHE(data:pd.DataFrame, label:str) -> pd.DataFrame:\n",
    "    encoder = OneHotEncoder()\n",
    "    \n",
    "    embarked_encoded = encoder.fit_transform(data[[label]]).toarray()\n",
    "    embarked_encoded_df = pd.DataFrame(\n",
    "        embarked_encoded,\n",
    "        columns=encoder.get_feature_names_out([label]),\n",
    "        index=data.index\n",
    "    )\n",
    "    \n",
    "    data = pd.concat([data, embarked_encoded_df], axis=1)\n",
    "    data.drop(label, axis=1,inplace=True)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def handle_cabin(data:pd.DataFrame) -> pd.DataFrame:\n",
    "    data[\"Cabin\"] = data[\"Cabin\"].fillna(\"C\")\n",
    "    cabin_floor = []\n",
    "    for cabin in data[\"Cabin\"]:\n",
    "        if cabin[0] == \"A\":\n",
    "            cabin_floor.append(\"A\")\n",
    "            continue\n",
    "        if cabin[0] == \"G\":\n",
    "            cabin_floor.append(\"G\")\n",
    "            continue\n",
    "            \n",
    "        cabin_floor.append(\"C\")\n",
    "    \n",
    "    data[\"Floor\"] = pd.Series(cabin_floor, index=data.index)\n",
    "    print()\n",
    "    data.drop(\"Cabin\",axis=1, inplace=True)\n",
    "     \n",
    "def handle_names(data:pd.DataFrame) -> pd.DataFrame:\n",
    "    # extract the title from the name\n",
    "    regex = r'(.+, (.+)\\..+)'\n",
    "    titles = data['Name'].str.extract(regex)[1]\n",
    "    \n",
    "    # encode the titles\n",
    "    encoded = []\n",
    "    common_titles = [\"Mr\", \"rare title\", \"Master\", \"Mrs\", \"Miss\"]\n",
    "    for title in titles:\n",
    "        if title in common_titles:\n",
    "            encoded.append(common_titles.index(title))\n",
    "            continue\n",
    "        \n",
    "        encoded.append(common_titles.index(\"rare title\"))\n",
    "            \n",
    "    data[\"Title\"] = pd.Series(encoded, index=data.index)\n",
    "    data.drop(\"Name\", axis=1, inplace=True)\n",
    "    \n",
    "    return data \n",
    "\n",
    "def handle_family_size(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    # add siblings, parents, childs, and wife/husband and the passenger themselves\n",
    "    family_size = data['SibSp'] + data['Parch'] + 1\n",
    "    family_size = family_size.values\n",
    "    # disretize family size\n",
    "    \n",
    "    for i, size in enumerate(family_size):\n",
    "        if size > 1 and size < 5:\n",
    "            family_size[i] = 2\n",
    "        if size > 4:\n",
    "            family_size[i] = 3\n",
    "    \n",
    "    data['Family'] = pd.Series(family_size, index=data.index)\n",
    "    data.drop([\"SibSp\", \"Parch\"], inplace=True, axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### get test and train dataset #####\n",
    "\n",
    "df_train = pd.read_csv(\"../data/train.csv\")\n",
    "train_data = preprocess(df_train)\n",
    "y = train_data[\"Survived\"]\n",
    "X = train_data.drop(\"Survived\", axis=1)\n",
    "\n",
    "df = pd.read_csv(\"../data/test.csv\")\n",
    "X_test = preprocess(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### save X #######\n",
    "X.to_csv(\"../data/X.csv\")\n",
    "X_test.to_csv(\"../data/X_test.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to recognize a pattern (what kind of people have more chance to die/survive) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 1, 0, 0, 0, 3, 1, 1, 2, 2, 0, 0, 2, 1, 3, 0, 1, 1, 0, 0, 2, 0, 2, 1, 0, 0, 2, 0, 4, 1, 2, 0, 0, 0, 0, 0, 2, 2, 1, 1, 0, 2, 2, 0, 0, 2, 0, 1, 3, 0, 1, 1, 0, 0, 2, 0, 2, 3, 0, 2, 0, 3, 0, 3, 1, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 3, 2, 0, 0, 2, 0, 2, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 2, 0, 2, 2, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 3, 0, 0, 2, 0, 0, 0, 1, 1, 0, 0, 2, 0, 0, 0, 1, 2, 1, 0, 0, 0, 0, 2, 0, 4, 4, 1, 0, 0, 0, 0, 2, 0, 0, 3, 0, 1, 0, 0, 3, 3, 1, 1, 0, 0, 0, 3, 2, 0, 0, 0, 3, 2, 0, 0, 2, 0, 3, 3, 2, 0, 1, 0, 0, 0, 1, 0, 2, 3, 1, 2, 0, 0, 2, 2, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 2, 0, 0, 0, 2, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 2, 0, 2, 0, 2, 0, 0, 2, 2, 0, 0, 0, 4, 2, 1, 0, 4, 0, 1, 0, 0, 1, 1, 1, 2, 2, 1, 0, 3, 0, 0, 2, 0, 0, 0, 1, 2, 0, 0, 1, 0, 2, 2, 2, 0, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 1, 0, 2, 0, 0, 0, 2, 0, 1, 2, 0, 0, 2, 0, 3, 2, 1, 0, 2, 2, 2, 1, 0, 0, 2, 1, 4, 2, 1, 0, 0, 2, 1, 0, 2, 0, 1, 1, 2, 2, 0, 0, 0, 1, 0, 0, 2, 0, 0, 3, 2, 0, 0, 0, 2, 2, 1, 3, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 0, 0, 1, 0, 0, 0, 1, 1, 2, 4, 0, 0, 0, 0, 2, 1, 2, 0, 0, 0, 2, 2, 0, 1, 0, 0, 3, 2, 0, 2, 0, 0, 0, 2, 1, 0, 2, 0, 4, 1, 0, 0, 2, 0, 2, 0, 0, 3, 0, 2, 0, 0, 2, 0, 0, 1, 1, 2, 0, 2, 0, 0, 0, 1, 0, 0, 1, 2, 0, 0, 0, 1, 1, 0, 0, 2, 2, 1, 0, 0, 1, 0, 0, 4, 0, 3, 2, 0, 2, 4, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 1, 2, 0, 0, 0, 0, 2, 3, 0, 0, 1, 0, 2, 1, 0, 0, 3, 0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 0, 2, 2, 2, 2, 0, 1, 0, 0, 0, 0, 0, 0, 4, 0, 0, 1, 0, 1, 0, 2, 0, 0, 1, 0, 0, 2, 0, 0, 0, 2, 0, 0, 1, 2, 2, 4, 2, 0, 2, 2, 2, 2, 0, 0, 0, 1, 0, 0, 3, 0, 0, 0, 0, 2, 0, 4, 0, 1, 1, 0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 0, 1, 0, 2, 0, 0, 2, 1, 1, 0, 2, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 2, 0, 0, 4, 1, 0, 0, 0, 0, 0, 0, 0, 1, 2, 1, 0, 2, 0, 0, 2, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 4, 2, 0, 0, 0, 0, 4, 0, 2, 2, 0, 0, 1, 0, 0, 4, 2, 0, 2, 0, 0, 4, 0, 2, 0, 2, 0, 2, 2, 0, 0, 1, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 2, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 4, 0, 0, 2, 0, 0, 1, 0, 2, 0, 0, 0, 1, 0, 2, 3, 4, 0, 0, 0, 0, 0, 2, 2, 0, 0, 2, 0, 0, 0, 0, 0, 1, 2, 0, 2, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 0, 4, 0, 2, 0, 0, 2, 3, 0, 0, 1, 3, 0, 0, 0, 4, 0, 0, 0, 1, 0, 1, 4, 2, 0, 0, 0, 0, 1, 0, 1, 0, 0, 2, 0, 1, 2, 1, 0, 0, 0, 0, 2, 3, 3, 0, 0, 0, 2, 0, 0, 0, 4, 1, 0, 1, 0, 1, 3, 3, 0, 0, 0, 2, 0, 1, 0, 0, 0, 2, 0, 0, 2, 0, 0, 3, 1, 0, 4, 1, 3, 0, 0, 3, 0, 1, 1, 3, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 4, 1, 3, 0, 2, 2, 1, 1, 1, 0, 1, 0, 0, 0, 1, 2, 0, 1, 2, 0, 0, 3, 0, 1, 0, 0, 1, 2, 0, 0, 0, 1, 1, 0, 2, 0, 0, 1, 4, 2, 2, 0, 0]\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m embark \u001b[39m=\u001b[39m df[df[\u001b[39m\"\u001b[39m\u001b[39mEmbarked\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mS\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mSurvived\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     14\u001b[0m title \u001b[39m=\u001b[39m df_preproc[df_preproc[\u001b[39m\"\u001b[39m\u001b[39mTitle\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m4\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mSurvived\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m---> 16\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m% o\u001b[39;00m\u001b[39mf women who survived:\u001b[39m\u001b[39m\"\u001b[39m, ratio(women))\n\u001b[1;32m     17\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m% o\u001b[39;00m\u001b[39mf first class\u001b[39m\u001b[39m\"\u001b[39m, ratio(p_class))\n\u001b[1;32m     18\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mage < 20\u001b[39m\u001b[39m\"\u001b[39m, ratio(age))\n",
      "Cell \u001b[0;32mIn[8], line 5\u001b[0m, in \u001b[0;36mratio\u001b[0;34m(survived)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mratio\u001b[39m(survived:pd\u001b[39m.\u001b[39mSeries) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mfloat\u001b[39m:\n\u001b[0;32m----> 5\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m100\u001b[39;49m \u001b[39m*\u001b[39;49m \u001b[39msum\u001b[39;49m(survived)\u001b[39m/\u001b[39;49m\u001b[39mlen\u001b[39;49m(survived)\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "# trying to identify the important factors\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def ratio(survived:pd.Series) -> float:\n",
    "    return 100 * sum(survived)/len(survived)\n",
    "\n",
    "df = pd.read_csv(\"../data/train.csv\")\n",
    "\n",
    "women = df[df[\"Sex\"] == 'female'][\"Survived\"]\n",
    "p_class = df[df[\"Pclass\"] == 1][\"Survived\"]\n",
    "age = df[df[\"Age\"] < 15][\"Survived\"]\n",
    "embark = df[df[\"Embarked\"] == \"S\"][\"Survived\"]\n",
    "\n",
    "print(\"% of women who survived:\", ratio(women))\n",
    "print(\"% of first class\", ratio(p_class))\n",
    "print(\"age < 20\", ratio(age))\n",
    "print(\"embark at S : \", ratio(embark))\n",
    "\n",
    "survivors_by_age = df[[\"Survived\", \"Age\"]][df[\"Survived\"] == 1] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 1, 0, 0, 0, 3, 1, 1, 2, 2, 0, 0, 2, 1, 3, 0, 1, 1, 0, 0, 2, 0, 2, 1, 0, 0, 2, 0, 4, 1, 2, 0, 0, 0, 0, 0, 2, 2, 1, 1, 0, 2, 2, 0, 0, 2, 0, 1, 3, 0, 1, 1, 0, 0, 2, 0, 2, 3, 0, 2, 0, 3, 0, 3, 1, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 3, 2, 0, 0, 2, 0, 2, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 2, 0, 2, 2, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 3, 0, 0, 2, 0, 0, 0, 1, 1, 0, 0, 2, 0, 0, 0, 1, 2, 1, 0, 0, 0, 0, 2, 0, 4, 4, 1, 0, 0, 0, 0, 2, 0, 0, 3, 0, 1, 0, 0, 3, 3, 1, 1, 0, 0, 0, 3, 2, 0, 0, 0, 3, 2, 0, 0, 2, 0, 3, 3, 2, 0, 1, 0, 0, 0, 1, 0, 2, 3, 1, 2, 0, 0, 2, 2, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 2, 0, 0, 0, 2, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 2, 0, 2, 0, 2, 0, 0, 2, 2, 0, 0, 0, 4, 2, 1, 0, 4, 0, 1, 0, 0, 1, 1, 1, 2, 2, 1, 0, 3, 0, 0, 2, 0, 0, 0, 1, 2, 0, 0, 1, 0, 2, 2, 2, 0, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 1, 0, 2, 0, 0, 0, 2, 0, 1, 2, 0, 0, 2, 0, 3, 2, 1, 0, 2, 2, 2, 1, 0, 0, 2, 1, 4, 2, 1, 0, 0, 2, 1, 0, 2, 0, 1, 1, 2, 2, 0, 0, 0, 1, 0, 0, 2, 0, 0, 3, 2, 0, 0, 0, 2, 2, 1, 3, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 0, 0, 1, 0, 0, 0, 1, 1, 2, 4, 0, 0, 0, 0, 2, 1, 2, 0, 0, 0, 2, 2, 0, 1, 0, 0, 3, 2, 0, 2, 0, 0, 0, 2, 1, 0, 2, 0, 4, 1, 0, 0, 2, 0, 2, 0, 0, 3, 0, 2, 0, 0, 2, 0, 0, 1, 1, 2, 0, 2, 0, 0, 0, 1, 0, 0, 1, 2, 0, 0, 0, 1, 1, 0, 0, 2, 2, 1, 0, 0, 1, 0, 0, 4, 0, 3, 2, 0, 2, 4, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 1, 2, 0, 0, 0, 0, 2, 3, 0, 0, 1, 0, 2, 1, 0, 0, 3, 0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 0, 2, 2, 2, 2, 0, 1, 0, 0, 0, 0, 0, 0, 4, 0, 0, 1, 0, 1, 0, 2, 0, 0, 1, 0, 0, 2, 0, 0, 0, 2, 0, 0, 1, 2, 2, 4, 2, 0, 2, 2, 2, 2, 0, 0, 0, 1, 0, 0, 3, 0, 0, 0, 0, 2, 0, 4, 0, 1, 1, 0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 0, 1, 0, 2, 0, 0, 2, 1, 1, 0, 2, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 2, 0, 0, 4, 1, 0, 0, 0, 0, 0, 0, 0, 1, 2, 1, 0, 2, 0, 0, 2, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 4, 2, 0, 0, 0, 0, 4, 0, 2, 2, 0, 0, 1, 0, 0, 4, 2, 0, 2, 0, 0, 4, 0, 2, 0, 2, 0, 2, 2, 0, 0, 1, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 2, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 4, 0, 0, 2, 0, 0, 1, 0, 2, 0, 0, 0, 1, 0, 2, 3, 4, 0, 0, 0, 0, 0, 2, 2, 0, 0, 2, 0, 0, 0, 0, 0, 1, 2, 0, 2, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 0, 4, 0, 2, 0, 0, 2, 3, 0, 0, 1, 3, 0, 0, 0, 4, 0, 0, 0, 1, 0, 1, 4, 2, 0, 0, 0, 0, 1, 0, 1, 0, 0, 2, 0, 1, 2, 1, 0, 0, 0, 0, 2, 3, 3, 0, 0, 0, 2, 0, 0, 0, 4, 1, 0, 1, 0, 1, 3, 3, 0, 0, 0, 2, 0, 1, 0, 0, 0, 2, 0, 0, 2, 0, 0, 3, 1, 0, 4, 1, 3, 0, 0, 3, 0, 1, 1, 3, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 4, 1, 3, 0, 2, 2, 1, 1, 1, 0, 1, 0, 0, 0, 1, 2, 0, 1, 2, 0, 0, 3, 0, 1, 0, 0, 1, 2, 0, 0, 0, 1, 1, 0, 2, 0, 0, 1, 4, 2, 2, 0, 0]\n",
      "titled :  46.42857142857143\n"
     ]
    }
   ],
   "source": [
    "# analyse preproc data\n",
    "\n",
    "df = preprocess(pd.read_csv('../data/train.csv'))\n",
    "\n",
    "title = df[df[\"Title\"] == 4][\"Survived\"]\n",
    "print(\"titled : \", ratio(title))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every models I tried are below : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### 0 survivors prediction ######\n",
    "\n",
    "zeros = np.zeros(len(X_test.index), dtype=int)\n",
    "pred = pd.DataFrame(zeros, index=X_test.index, columns=[\"Survived\"])\n",
    "pred.to_csv(\"../data/the_reaper_prediction.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Survived\n",
      "PassengerId          \n",
      "892                 0\n",
      "893                 0\n",
      "894                 0\n",
      "895                 0\n",
      "896                 1\n",
      "...               ...\n",
      "1305                0\n",
      "1306                1\n",
      "1307                0\n",
      "1308                0\n",
      "1309                0\n",
      "\n",
      "[418 rows x 1 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "######## simple regression #########\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# X and y are the preprocessed data\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "\n",
    "model.fit(X,y)\n",
    "pred = model.predict(X_test)\n",
    "\n",
    "pred_df = pd.DataFrame(pred, index=X_test.index, columns=[\"Survived\"])\n",
    "\n",
    "print(pred_df)\n",
    "pred_df.to_csv(\"../data/prediction.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/student/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/student/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/student/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/student/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/student/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/student/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/student/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/student/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/student/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/student/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/student/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/student/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/student/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/student/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/student/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/student/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/student/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/student/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/student/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/student/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/student/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/student/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/student/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/student/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/student/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/student/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/student/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "35 fits failed out of a total of 70.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/student/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/student/.local/lib/python3.10/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/home/student/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/student/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/student/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan 0.68131944        nan 0.7307137         nan 0.79688657\n",
      "        nan 0.7890214         nan 0.79238591        nan 0.79239219\n",
      "        nan 0.78564434]\n",
      "  warnings.warn(\n",
      "/home/student/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# grid search (find the best model)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# X and y are the preprocessed data\n",
    "\n",
    "# run a gridsearch\n",
    "model = LogisticRegression()\n",
    "param_grid = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "}\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "grid_search.fit(X,y)\n",
    "best_model = grid_search.best_estimator_\n",
    "pred = best_model.predict(X_test)\n",
    "\n",
    "\n",
    "pred_df = pd.DataFrame(pred, index=X_test.index, columns=[\"Survived\"])\n",
    "pred_df.to_csv(\"../data/gridsearch_prediction.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/student/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/student/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/student/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/student/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1151, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/home/student/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1209, in compute_loss\n        return self.compiled_loss(\n    File \"/home/student/.local/lib/python3.10/site-packages/keras/src/engine/compile_utils.py\", line 252, in __call__\n        self.build(y_pred)\n    File \"/home/student/.local/lib/python3.10/site-packages/keras/src/engine/compile_utils.py\", line 194, in build\n        self._losses = tf.nest.map_structure(\n    File \"/home/student/.local/lib/python3.10/site-packages/keras/src/engine/compile_utils.py\", line 365, in _get_loss_object\n        loss = losses_mod.get(loss)\n    File \"/home/student/.local/lib/python3.10/site-packages/keras/src/losses.py\", line 2965, in get\n        return deserialize(identifier, use_legacy_format=use_legacy_format)\n    File \"/home/student/.local/lib/python3.10/site-packages/keras/src/losses.py\", line 2912, in deserialize\n        return legacy_serialization.deserialize_keras_object(\n    File \"/home/student/.local/lib/python3.10/site-packages/keras/src/saving/legacy/serialization.py\", line 537, in deserialize_keras_object\n        raise ValueError(\n\n    ValueError: Unknown loss function: 'accuracy'. Please ensure you are using a `keras.utils.custom_object_scope` and that this object is included in the scope. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[82], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m X \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39mfit_transform(X)\n\u001b[1;32m     18\u001b[0m X_test \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39mtransform(X_test)\n\u001b[0;32m---> 20\u001b[0m model\u001b[39m.\u001b[39;49mfit(X, y, epochs\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n\u001b[1;32m     22\u001b[0m pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[1;32m     23\u001b[0m pred \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mround(pred)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filec9gfr5h4.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/student/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/student/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/student/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/student/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1151, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/home/student/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1209, in compute_loss\n        return self.compiled_loss(\n    File \"/home/student/.local/lib/python3.10/site-packages/keras/src/engine/compile_utils.py\", line 252, in __call__\n        self.build(y_pred)\n    File \"/home/student/.local/lib/python3.10/site-packages/keras/src/engine/compile_utils.py\", line 194, in build\n        self._losses = tf.nest.map_structure(\n    File \"/home/student/.local/lib/python3.10/site-packages/keras/src/engine/compile_utils.py\", line 365, in _get_loss_object\n        loss = losses_mod.get(loss)\n    File \"/home/student/.local/lib/python3.10/site-packages/keras/src/losses.py\", line 2965, in get\n        return deserialize(identifier, use_legacy_format=use_legacy_format)\n    File \"/home/student/.local/lib/python3.10/site-packages/keras/src/losses.py\", line 2912, in deserialize\n        return legacy_serialization.deserialize_keras_object(\n    File \"/home/student/.local/lib/python3.10/site-packages/keras/src/saving/legacy/serialization.py\", line 537, in deserialize_keras_object\n        raise ValueError(\n\n    ValueError: Unknown loss function: 'accuracy'. Please ensure you are using a `keras.utils.custom_object_scope` and that this object is included in the scope. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.\n"
     ]
    }
   ],
   "source": [
    "# neural-network with logistic regression\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_shape=[X.shape[1]], activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(\n",
    "    loss='accuracy',\n",
    "    optimizer='adam',\n",
    ")\n",
    "\n",
    "indexs = X_test.index\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model.fit(X, y, epochs=1000, batch_size=10)\n",
    "\n",
    "pred = model.predict(X_test)\n",
    "pred = np.round(pred)\n",
    "print(pred)\n",
    "\n",
    "pred_df = pd.DataFrame(pred, index=indexs, columns=[\"Survived\"], dtype=int)\n",
    "pred_df.to_csv(\"../data/neural_network_pred.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100)\n",
    "model.fit(X,y)\n",
    "pred = model.predict(X_test)\n",
    "\n",
    "pred_df = pd.DataFrame(pred, index=X_test.index, columns=[\"Survived\"])\n",
    "pred_df.to_csv(\"../predictions/randomForest3.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
